{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG Pipeline Demo\n",
    "\n",
    "This notebook demonstrates a complete RAG pipeline for enterprise document analysis with:\n",
    "- PDF ingestion with text and table extraction\n",
    "- Hybrid indexing (semantic + metadata)\n",
    "- Retrieval with explainability\n",
    "- Policy guardrails for safety checking\n",
    "- Structured JSON output with citations\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's set up our environment and generate sample documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Colab: Install dependencies\n",
    "# !pip install openai chromadb pymupdf tiktoken fpdf2 python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "# Set OpenAI API key (or use .env file)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-key-here\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample PDFs\n",
    "%run ../scripts/generate_sample_pdfs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Document Ingestion\n",
    "\n",
    "We start by parsing PDFs to extract text and detect tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ingestion.pdf_parser import PDFParser\n",
    "\n",
    "# Initialize parser\n",
    "parser = PDFParser(extract_images=True, image_dpi=150)\n",
    "\n",
    "# Parse all PDFs in data directory\n",
    "pdf_dir = Path.cwd().parent / \"data\" / \"pdfs\"\n",
    "documents = parser.parse_directory(pdf_dir)\n",
    "\n",
    "print(f\"Parsed {len(documents)} documents:\")\n",
    "for doc in documents:\n",
    "    pages_with_tables = len(doc.get_pages_with_tables())\n",
    "    print(f\"  - {doc.filename}: {doc.total_pages} pages, {pages_with_tables} with tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview extracted text from first document\n",
    "doc = documents[0]\n",
    "print(f\"=== {doc.filename} ===\")\n",
    "print(doc.get_full_text()[:1500])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Table Extraction with Vision LLM\n",
    "\n",
    "For pages with tables, we use GPT-4V to extract structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from ingestion.table_extractor import TableExtractor\n",
    "\n",
    "client = OpenAI()\n",
    "table_extractor = TableExtractor(client=client, model=\"gpt-4o\")\n",
    "\n",
    "# Extract tables from pages that have them\n",
    "all_tables = []\n",
    "for doc in documents:\n",
    "    tables = table_extractor.extract_from_pages(doc.pages, only_table_pages=True)\n",
    "    all_tables.extend(tables)\n",
    "    print(f\"{doc.filename}: Extracted {len(tables)} tables\")\n",
    "\n",
    "print(f\"\\nTotal tables extracted: {len(all_tables)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview an extracted table\n",
    "if all_tables:\n",
    "    table = all_tables[0]\n",
    "    print(f\"Table from {table.source_file}, Page {table.page_num}\")\n",
    "    print(f\"Summary: {table.table_summary}\")\n",
    "    print(f\"Headers: {table.headers}\")\n",
    "    print(f\"Rows: {table.row_count}\")\n",
    "    print(f\"\\nJSON Data:\")\n",
    "    import json\n",
    "    print(json.dumps(table.table_json, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Chunking Strategy\n",
    "\n",
    "Our chunking strategy:\n",
    "1. **Tables are never split** - kept as atomic units\n",
    "2. **Text uses semantic boundaries** - paragraphs preferred over arbitrary splits\n",
    "3. **Overlap for context** - maintains continuity between chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexing.chunker import DocumentChunker, ChunkType\n",
    "\n",
    "chunker = DocumentChunker(chunk_size=512, chunk_overlap=50)\n",
    "\n",
    "all_chunks = []\n",
    "\n",
    "# Chunk text content\n",
    "for doc in documents:\n",
    "    for page in doc.pages:\n",
    "        chunks = chunker.chunk_text(\n",
    "            text=page.text,\n",
    "            source_file=doc.filename,\n",
    "            page_num=page.page_num,\n",
    "            chunk_id_prefix=f\"{doc.filename}_p{page.page_num}\"\n",
    "        )\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "# Chunk tables (as single units)\n",
    "for i, table in enumerate(all_tables):\n",
    "    chunk = chunker.chunk_table(\n",
    "        table_json=table.table_json,\n",
    "        table_summary=table.table_summary,\n",
    "        source_file=table.source_file,\n",
    "        page_num=table.page_num,\n",
    "        chunk_id=f\"table_{i}\"\n",
    "    )\n",
    "    all_chunks.append(chunk)\n",
    "\n",
    "print(f\"Total chunks: {len(all_chunks)}\")\n",
    "print(f\"Text chunks: {sum(1 for c in all_chunks if c.chunk_type == ChunkType.TEXT)}\")\n",
    "print(f\"Table chunks: {sum(1 for c in all_chunks if c.chunk_type == ChunkType.TABLE)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: Hybrid Indexing\n",
    "\n",
    "We build a hybrid index combining:\n",
    "- **Vector store** for semantic search\n",
    "- **Metadata store** for structured table data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexing.hybrid_index import HybridIndex\n",
    "\n",
    "# Initialize index (in-memory for demo)\n",
    "index = HybridIndex(\n",
    "    collection_name=\"demo_docs\",\n",
    "    openai_client=client,\n",
    "    embedding_model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "# Clear any existing data\n",
    "index.clear()\n",
    "\n",
    "# Add all chunks\n",
    "added = index.add_chunks(all_chunks)\n",
    "print(f\"Added {added} chunks to index\")\n",
    "\n",
    "# Show stats\n",
    "stats = index.get_stats()\n",
    "print(f\"\\nIndex stats: {stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5: Retrieval with Explainability\n",
    "\n",
    "Our retriever explains why each chunk was selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retrieval.hybrid_retriever import HybridRetriever\n",
    "\n",
    "retriever = HybridRetriever(\n",
    "    index=index,\n",
    "    openai_client=client,\n",
    "    relevance_threshold=0.3,\n",
    "    explain_retrievals=True\n",
    ")\n",
    "\n",
    "# Test retrieval\n",
    "query = \"What is the maximum operating temperature?\"\n",
    "result = retriever.retrieve(query, n_results=3)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Retrieved {len(result.chunks)} chunks (filtered {result.filtered_count})\\n\")\n",
    "\n",
    "for i, chunk in enumerate(result.chunks, 1):\n",
    "    print(f\"--- Chunk {i} ---\")\n",
    "    print(f\"Source: {chunk.source_file}, Page {chunk.page_num}\")\n",
    "    print(f\"Type: {chunk.chunk_type}\")\n",
    "    print(f\"Relevance: {chunk.relevance_score:.2f}\")\n",
    "    print(f\"Reasons: {[r.value for r in chunk.retrieval_reasons]}\")\n",
    "    print(f\"Explanation: {chunk.explanation}\")\n",
    "    print(f\"Content preview: {chunk.content[:200]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 6: Reasoning Agent with Guardrails\n",
    "\n",
    "The reasoning agent:\n",
    "1. Uses chain-of-thought reasoning\n",
    "2. Generates citations for every claim\n",
    "3. Extracts numerical values\n",
    "4. Applies policy guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.guardrails import create_manufacturing_guardrail\n",
    "from agent.reasoning import ReasoningAgent\n",
    "\n",
    "# Set up guardrails for manufacturing domain\n",
    "guardrail = create_manufacturing_guardrail()\n",
    "\n",
    "# Initialize reasoning agent\n",
    "agent = ReasoningAgent(\n",
    "    retriever=retriever,\n",
    "    guardrail=guardrail,\n",
    "    openai_client=client,\n",
    "    model=\"gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Query about temperature (should trigger guardrail)\n",
    "query = \"What is the current operating temperature and is it safe?\"\n",
    "result = agent.reason(query, n_chunks=5)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"\\nAnswer: {result.answer}\")\n",
    "print(f\"\\nConfidence: {result.confidence:.0%}\")\n",
    "print(f\"\\nExtracted Values: {result.extracted_values}\")\n",
    "print(f\"\\nRisk Flags: {result.risk_flags}\")\n",
    "print(f\"\\nCitations: {result.citations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Query about product pricing\n",
    "query = \"What are the prices for CloudServer Pro models and what's included in the warranty?\"\n",
    "result = agent.reason(query, n_chunks=5)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"\\nAnswer: {result.answer}\")\n",
    "print(f\"\\nConfidence: {result.confidence:.0%}\")\n",
    "print(f\"\\nExtracted Values: {result.extracted_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Query about budget\n",
    "query = \"What was the total Q4 budget variance and which categories exceeded their budget?\"\n",
    "result = agent.reason(query, n_chunks=5)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"\\nAnswer: {result.answer}\")\n",
    "print(f\"\\nExtracted Values: {result.extracted_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 7: Structured Output Synthesis\n",
    "\n",
    "Final output includes:\n",
    "- Executive summary\n",
    "- Key findings\n",
    "- Extracted data\n",
    "- Risk flags\n",
    "- Full citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from output.synthesizer import OutputSynthesizer\n",
    "\n",
    "synthesizer = OutputSynthesizer(openai_client=client)\n",
    "\n",
    "# Generate structured output\n",
    "query = \"Analyze the equipment safety status and identify any risks\"\n",
    "reasoning_result = agent.reason(query, n_chunks=5)\n",
    "retrieval_result = retriever.retrieve(query, n_results=5)\n",
    "\n",
    "output = synthesizer.synthesize(\n",
    "    query=query,\n",
    "    reasoning_output=reasoning_result,\n",
    "    retrieval_result=retrieval_result\n",
    ")\n",
    "\n",
    "# Display formatted output\n",
    "print(synthesizer.format_for_display(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get JSON output\n",
    "print(\"\\n=== JSON OUTPUT ===\")\n",
    "print(output.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Examples\n",
    "\n",
    "Let's test the pipeline with various query types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test queries covering different scenarios\n",
    "test_queries = [\n",
    "    # Numerical extraction\n",
    "    \"What is the maximum voltage rating?\",\n",
    "    \n",
    "    # Table query\n",
    "    \"Compare the RAM and storage across CloudServer Pro models\",\n",
    "    \n",
    "    # Risk detection\n",
    "    \"Are there any safety concerns with the current equipment operation?\",\n",
    "    \n",
    "    # Financial data\n",
    "    \"Which expense categories were over budget in Q4?\",\n",
    "    \n",
    "    # Hallucination test (info not in docs)\n",
    "    \"What is the CEO's name?\",\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Query: {query}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    result = agent.reason(query, n_chunks=3)\n",
    "    print(f\"Answer: {result.answer[:300]}...\" if len(result.answer) > 300 else f\"Answer: {result.answer}\")\n",
    "    print(f\"Confidence: {result.confidence:.0%}\")\n",
    "    \n",
    "    if result.risk_flags:\n",
    "        print(f\"Risk Flags: {result.risk_flags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This pipeline demonstrates:\n",
    "\n",
    "1. **Visual Ingestion**: PDF parsing with image extraction for vision model analysis\n",
    "2. **Smart Chunking**: Tables kept intact, text split semantically\n",
    "3. **Hybrid Search**: Vector similarity + metadata filtering\n",
    "4. **Explainable Retrieval**: Every chunk includes why it was selected\n",
    "5. **Grounded Reasoning**: Strict citation requirements prevent hallucination\n",
    "6. **Policy Guardrails**: Automatic risk detection for domain-specific limits\n",
    "7. **Structured Output**: JSON with citations, extracted data, and risk flags"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
